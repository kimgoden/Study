{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled6.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOOlpxyW+pqaUfbW5JE08bL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kimgoden/Study/blob/main/Decison%20Tree.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FBFO3gw72bJ2"
      },
      "source": [
        "# 머신러닝 모델"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "md-z9ftf3CRD"
      },
      "source": [
        "## Decison Tree\n",
        " - Decison Tree(결정트리) 는 분류, 회귀 모두 가능한 지도 학습 모델 중 하나다.\n",
        " - 결정 트리는 특정 기준(질문)에 따라 데이터를 구분하는 모델이다.\n",
        " - 이러한 방식으로 데이터를 분류하는 것은 스무고개와 유사한 방식으로 이루어진다.\n",
        "\n",
        " ![](/images/DecisonTree/tt.png)\n",
        "\n",
        " "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oZwt0xQn55ox"
      },
      "source": [
        "### 결정트리 알고리즘\n",
        "- 용어\n",
        "   - Node(노드) : 결정트리에서 질문이나 정답을 담은 네모 상자(분기점)\n",
        "   - Root Ndoe(루트노드) : 깊이가 0인 가장 위의 노드\n",
        "   - Leaf Node(리프노드) : 자식 노드가 없는 마지막 노드\n",
        "- 진행과정\n",
        "  1. 첫번째로 root node(꼭대기)에서 시작한다.\n",
        "  2. 다리가 있나요? 라는 질문을 검사한다(조건에 따라 좌우 분기)\n",
        "  3. 만약 '아니' 라면 오른쪽으로 이동해 root node에서 했던 조건의 검사를 실시하여 반복한다.\n",
        "  4. 마지막에 leaf node(끝) 에 도달했을 때, 추가적인 조건 검사 없이 가장 많은 클래스의 비중을 차지하고 있는 곳으로 클래스를 예측하게된다.(토끼,강아지)(고래,소라고동)\n",
        "\n",
        "\n",
        "- 결정 트리의 장점은 스케일이나 평균으 원점에 맞추는 것같은 데이터 전처리가 거의 필요하지 않다. 또 매우 직관적이고 이해하기 쉬우며 동시에 해석력이 좋다.\n",
        "\n",
        "- 반대로 방식이 매우 단순하기 때문에 이를 극복하기 위해 랜덤 포레스트(Random Forest)를 사용할 수 있다.\n",
        "- 그러나 새로운 데이터가 반영될 때 마다 숲(Forest)를 다시 만들어줘야 하기 때문에 풀고자하는 문제에 비해 계산량이 많아진다는 단점이 있다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IHGF9pCuA18a"
      },
      "source": [
        "### Decison Tree 예제\n",
        "- 결정트리를 이해하기 쉽게 `Sklearn`에서 제공하는 데이터셋을 이용한 예제다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jIpLRKN_2aI7",
        "outputId": "fb079ae7-c866-487c-8ddd-4121e130b0b6"
      },
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "# 싸이킷런 데이터를 의사결정 트리를 임포트 해준다.\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "# 싸이킷런에서 제공하는 유방암 데이터를 가져온다.\n",
        "from sklearn.model_selection import train_test_split\n",
        "# 분석에 이용할 train, test 함수를 선언해준다.\n",
        "\n",
        "cancer = load_breast_cancer()\n",
        "# 샘플 데이터(유방암 데이터)를 로드해준다.\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    cancer.data, cancer.target, stratify=cancer.target, random_state=42)\n",
        "# 훈련, 테스트 데이터를 셔플해준다.\n",
        "\n",
        "treeAll = DecisionTreeClassifier(random_state=0)\n",
        "# 의사결정 트리 선언\n",
        "\n",
        "treeAll.fit(X_train, y_train)\n",
        "# 훈련 시작(모든 리프 노드를 사용한다)\n",
        "\n",
        "print(\"훈련 세트 정확도: {:.3f}\".format(tree.score(X_train, y_train)))\n",
        "print(\"테스트 세트 정확도: {:.3f}\".format(tree.score(X_test, y_test)))\n",
        "#점수를 출력한다."
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "훈련 세트 정확도: 0.988\n",
            "테스트 세트 정확도: 0.951\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4FjUQCPE4YM5",
        "outputId": "01fc4434-6739-4194-cff1-b53388e641a5"
      },
      "source": [
        "treeLimit = DecisionTreeClassifier(max_depth=4, random_state=0)\n",
        "#의사결정 트리 선언, 이때 트리 깊이(분기)를 제한해준다.\n",
        "\n",
        "treeLimit.fit(X_train, y_train)\n",
        "#훈련시작, 이때 리프노드의 깊이를 제한한다.\n",
        "\n",
        "print(\"훈련 세트 정확도: {:.3f}\".format(tree.score(X_train, y_train)))\n",
        "print(\"테스트 세트 정확도: {:.3f}\".format(tree.score(X_test, y_test)))\n",
        "#점수를 출력한다.\n",
        "\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "훈련 세트 정확도: 0.988\n",
            "테스트 세트 정확도: 0.951\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "330vhcIACID5"
      },
      "source": [
        "from sklearn.tree import export_graphviz\n",
        "\n",
        "export_graphviz(treeLimit, out_file=\"mytree.dot\")\n",
        "with open(\"mytree.dot\") as f:\n",
        "    dot_graph = f.read()\n",
        "graphviz.Source(dot_graph)\n",
        "\n",
        "(graph,) = pydot.graph_from_dot_file('mytree.dot', encoding='utf8')\n",
        "\n",
        "graph.write_png('mytree,png')"
      ],
      "execution_count": 20,
      "outputs": []
    }
  ]
}